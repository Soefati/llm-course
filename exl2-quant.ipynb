{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation of exllamav2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!git clone https://github.com/turboderp/exllamav2\n",
    "%cd /content/exllamav2\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset and model to quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/exllamav2/\n",
    "!rm -r dataset\n",
    "!mkdir dataset\n",
    "%cd dataset\n",
    "!wget https://huggingface.co/datasets/wikitext/resolve/refs%2Fconvert%2Fparquet/wikitext-2-v1/test/0000.parquet\n",
    "\n",
    "!pip install huggingface_hub\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "# Select model\n",
    "repo_id = \"meta-llama/Llama-2-13b\"\n",
    "\n",
    "# Select branch\n",
    "revision=\"main\"\n",
    "local_dir=f\"/content/{repo_id.replace('/', '_')}\"\n",
    "%mkdir $local_dir\n",
    "# Download model\n",
    "from huggingface_hub import snapshot_download\n",
    "snapshot_download(repo_id=repo_id, local_dir=f\"/content/{repo_id.replace('/', '_')}\")\n",
    "\n",
    "print(f\"Model dir: '/content/{repo_id.replace('/', '_')}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/exllamav2/\n",
    "!git pull --rebase --autostash\n",
    "%cd /content\n",
    "!mkdir output\n",
    "%cd /content/exllamav2/\n",
    "!python convert.py \\\n",
    "    -i \"/content/Llama-2-13b\" \\\n",
    "    -o \"/content/EXL2\" \\\n",
    "    -c dataset \\\n",
    "    -b 9 \\\n",
    "    -m \"/content/measurement.json\" \\\n",
    "    -ss 0 \\\n",
    "    -hb 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload quantized model to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=\"/content/models/\",\n",
    "    repo_id=\"your repo id\",\n",
    "    revision=\"main\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
